---
title: "Lecture 10: Beginning optimization"
author: "Ciaran Evans"
output: beamer_presentation
editor_options: 
  chunk_output_type: console
---

## Course logistics

* Thanks for feedback!
* Sounds like pace is ok -- I will keep checking in
* Tweak to grading policy: mastery at the question level, not the assignment level
    * Strictly better for your course grade
    * Won't penalize correct questions for mistakes on other questions
    * Resubmission still part of system
* Using other languages: if you would like to practice a different language for the R coding assignments, I am generally ok with that. Talk to me about it if you are interested
* Project 1 released, due March 5

## Motivation: regression models

Data on 116 sparrows from Kent Island, New Brunswick.

* `Weight`: the weight of the sparrow (in grams)
* `WingLength`: the sparrowâ€™s wing length (in mm)

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=2.5, fig.height=2}
library(Stat2Data)
library(tidyverse)
data("Sparrows")

Sparrows |>
  ggplot(aes(x = WingLength, y = Weight)) +
  geom_point(size = 0.75) +
  theme_bw()
```

**Question:** How could I model the relationship between these two variables?

## Motivation: linear regression

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=3, fig.height=2.5}
library(Stat2Data)
library(tidyverse)
data("Sparrows")

Sparrows |>
  ggplot(aes(x = WingLength, y = Weight)) +
  geom_point(size = 0.75) +
  theme_bw() +
  geom_smooth(method = "lm", se=F)
```

**Question:** How do I get the fitted regression line?

## Motivation: linear regression

**Population model:** $\text{Weight}_i = \beta_0 + \beta_1 \text{WingLength}_i + \varepsilon_i$

**Fitted model:** $\widehat{\text{Weight}}_i = \widehat{\beta}_0 + \widehat{\beta}_1 \text{WingLength}_i$

**In R:** 

```{r, eval=F}
lm(Weight ~ WingLength, data = Sparrows)
```

\begin{verbatim}
Coefficients:
(Intercept)   WingLength  
     1.3655       0.4674 
\end{verbatim}

**Mathematically:** $\widehat{\beta}_0, \widehat{\beta}_1$ are the values which *minimize* the residual sum of squares:

$$RSS(\beta_0, \beta_1) = \sum \limits_{i=1}^n (\text{Weight}_i - \beta_0 - \beta_1 \text{WingLength}_i)^2$$

## Overview: Optimization

**Definition:** *Optimization* is the problem of finding values that minimize or maximize some function.

**Example:** 

$$RSS(\beta_0, \beta_1) = \sum \limits_{i=1}^n (\text{Weight}_i - \beta_0 - \beta_1 \text{WingLength}_i)^2$$

* $RSS(\beta_0, \beta_1)$ is a function of $\beta_0$ and $\beta_1$
* We want to find the values of $\beta_0$ and $\beta_1$ that *minimize* this function

**Question:** How could we go about minimizing this function?

\vspace{2cm}

## Overview: types of optimization methods

In this course, we will focus on two main types of optimization

\vspace{0.5cm}

* **Derivative-based methods:** use the derivative (and possibly higher-order derivatives too) to find a maximum/minimum.

\vspace{0.5cm}

* **Derivative-free methods:** do not use any derivatives (or approximations to derivatives).

\vspace{0.5cm}

We will begin with derivative-free methods.

## Optimization without a derivative

$$RSS(\beta_0, \beta_1) = \sum \limits_{i=1}^n (\text{Weight}_i - \beta_0 - \beta_1 \text{WingLength}_i)^2$$

**Question:** How would you try to minimize $RSS(\beta_0, \beta_1)$ *without* taking a derivative? Brainstorm with your neighbor for 1-2 minutes, then we will discuss as a class.

\vspace{5cm}


## Initial idea: grid search

* Define a set of values for $\beta_0, \beta_1$
* Calculate $RSS(\beta_0, \beta_1)$ for each pair of values
* Choose the values which minimize $RSS(\beta_0, \beta_1)$

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=2.5, fig.height=2}
Sparrows |>
  ggplot(aes(x = WingLength, y = Weight)) +
  geom_point(size = 0.75) +
  theme_bw()
```

**Question:** What is a reasonable range of values to consider for $\beta_0$ and $\beta_1$?

## Initial idea: grid search

Consider values:

* $\beta_0 = -5, \ -4.9, \ -4.8, ..., \ 4.8, \ 4.9, \ 5$
* $\beta_1 = 0, \ 0.05, ..., \ 1.45, \ 1.5$

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
beta0_values <- seq(-5, 5, 0.1)
beta1_values <- seq(0, 1.5, 0.05)
beta_grid <- expand.grid(beta0_values, beta1_values)

beta_grid |>
  ggplot(aes(x = Var1, y = Var2)) +
  geom_point(size=0.25) +
  theme_bw() +
  labs(x = "Beta0 values", y = "Beta1 values", title = "Grid of possible values")
```

## Initial idea: grid search

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
beta0_values <- seq(-5, 5, 0.1)
beta1_values <- seq(0, 1.5, 0.05)
beta_grid <- expand.grid(beta0_values, beta1_values)

beta_grid |>
  ggplot(aes(x = Var1, y = Var2)) +
  geom_point(size=0.25) +
  theme_bw() +
  labs(x = "Beta0 values", y = "Beta1 values", title = "Grid of possible values")
```

Now we calculate $RSS(\beta_0, \beta_1)$ for each possible pair in the grid.

## Initial idea: grid search

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
beta0_values <- seq(-5, 5, 0.1)
beta1_values <- seq(0, 1.5, 0.05)
beta_grid <- expand.grid(beta0_values, beta1_values)

rss_vals <- rep(NA, nrow(beta_grid))

for(i in 1:length(rss_vals)){
  rss_vals[i] <- sum((Sparrows$Weight - beta_grid[i, 1] - beta_grid[i, 2]*Sparrows$WingLength)^2)
}

beta_grid |>
  mutate(rss = rss_vals) |>
  ggplot(aes(x = Var1, y = Var2, color = log(rss))) +
  geom_point() +
  theme_bw() +
  labs(x = "Beta0 values", y = "Beta1 values", title = "Grid of possible values",
       color = "RSS") +
  scale_color_gradient(low="blue", high="yellow")
```

## Initial idea: grid search

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
beta_grid |>
  mutate(rss = rss_vals) |>
  filter(Var1 >= 0, Var1 <= 2, Var2 >= 0, Var2 <= 0.7) |>
  ggplot(aes(x = Var1, y = Var2, color = log(rss))) +
  geom_point() +
  theme_bw() +
  labs(x = "Beta0 values", y = "Beta1 values", title = "Grid of possible values",
       color = "RSS") +
  #scale_color_gradientn(colors = rev(RColorBrewer::brewer.pal(11, "Spectral")))+
  scale_color_gradient(low="blue", high="yellow")
```

Combination with smallest RSS: $\beta_0 =1.8, \ \beta_1 = 0.45$


## Grid search: limitations

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
beta_grid |>
  mutate(rss = rss_vals) |>
  ggplot(aes(x = Var1, y = Var2, color = log(rss))) +
  geom_point() +
  theme_bw() +
  labs(x = "Beta0 values", y = "Beta1 values", title = "Grid of possible values",
       color = "RSS") +
  scale_color_gradient(low="blue", high="yellow")
```

**Question:** What are some disadvantages of this grid search procedure?

## Grid search: limitations

For the basic grid search procedure described here:

* Does not scale well to higher dimensions (more coefficients)
* Requires a good selection of grid points
* Doesn't consider new values
* Can't tell when it is "close" to an optimal value

## Better approach: compass search

**Step 1:** Start with an initial guess for $\beta_0$ and $\beta_1$, and calculate $RSS(\beta_0, \beta_1)$:

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
df <- data.frame(b0 = 0, b1 = 1, rss = 20848.66)
df |>
  ggplot(aes(x = b0, y = b1, label = paste0("RSS = ", rss))) +
  geom_point() +
  theme_classic() +
  labs(x = "Beta0", y = "Beta1") +
  scale_x_continuous(limits=c(-1, 2)) +
  scale_y_continuous(limits = c(0, 1.5)) +
  geom_text(nudge_x = 0.5, nudge_y = 0.15)
```


## Better approach: compass search

**Step 2:** Try test points in the four directions around the initial point:

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
library(ggrepel)
df <- data.frame(b0 = c(-0.3, 0, 0, 0, 0.3),
                 b1 = c(1, 1, 0.7, 1.3, 1), 
                 rss = c(19941.46, 20848.66, 3198.25, 54374.89, 21776.74))
df |>
  ggplot(aes(x = b0, y = b1, label = rss)) +
  geom_point() +
  theme_classic() +
  labs(x = "Beta0", y = "Beta1") +
  scale_x_continuous(limits=c(-1, 2)) +
  scale_y_continuous(limits = c(0, 1.5)) +
  geom_text_repel(size=3)
```

Which of the 5 points is the best current guess for $(\beta_0, \beta_1)$?

## Better approach: compass search

**Step 3:** If one of the four new points is better, move to the new best point:

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
df <- data.frame(b0 = c(-0.3, 0, 0, 0, 0.3),
                 b1 = c(0.7, 0.7, 0.4, 1, 0.7), 
                 rss = c(2861.47, 3198.25, 1423.66, 20848.66, 3555.91))
df |>
  ggplot(aes(x = b0, y = b1, label = rss)) +
  geom_point() +
  theme_classic() +
  labs(x = "Beta0", y = "Beta1") +
  scale_x_continuous(limits=c(-1, 2)) +
  scale_y_continuous(limits = c(0, 1.5)) +
  geom_text_repel(size=3)
```

Where do we move next?

## Better approach: compass search

**Step 3:** If one of the four new points is better, move to the new best point:

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
df <- data.frame(b0 = c(-0.3, 0, 0, 0, 0.3),
                 b1 = c(0.4, 0.4, 0.1, 0.7, 0.4), 
                 rss = c(1657.3, 1423.66, 15524.89, 3198.25, 1210.9))
df |>
  ggplot(aes(x = b0, y = b1, label = rss)) +
  geom_point() +
  theme_classic() +
  labs(x = "Beta0", y = "Beta1") +
  scale_x_continuous(limits=c(-1, 2)) +
  scale_y_continuous(limits = c(0, 1.5)) +
  geom_text_repel(size=3)
```

Where do we move next?

## Better approach: compass search

**Step 3:** If one of the four new points is better, move to the new best point:

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
df <- data.frame(b0 = c(0, 0.3, 0.3, 0.3, 0.6),
                 b1 = c(0.4, 0.4, 0.1, 0.7, 0.4), 
                 rss = c(1423.66, 1210.9, 14741.71, 3555.91, 1019.02))
df |>
  ggplot(aes(x = b0, y = b1, label = rss)) +
  geom_point() +
  theme_classic() +
  labs(x = "Beta0", y = "Beta1") +
  scale_x_continuous(limits=c(-1, 2)) +
  scale_y_continuous(limits = c(0, 1.5)) +
  geom_text_repel(size=3)
```

Where do we move next?

## Better approach: compass search

After a few more iterations, we end up here:

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
rss <- function(beta){ sum((Sparrows$Weight - beta[1] -beta[2]*Sparrows$WingLength)^2)}
cur_point <- c(3.3, 0.4)
step_size <- 0.3
test_points <- rbind(cur_point,
                     cur_point + step_size*c(0, 1),
                     cur_point + step_size*c(1, 0),
                     cur_point + step_size*c(0, -1),
                     cur_point + step_size*c(-1, 0))
rss_vals <- apply(test_points, 1, rss)
df <- data.frame(b0 = test_points[,1],
                 b1 = test_points[,2], 
                 rss = rss_vals)
df |>
  ggplot(aes(x = b0, y = b1, label = rss)) +
  geom_point() +
  theme_classic() +
  labs(x = "Beta0", y = "Beta1") +
  scale_x_continuous(limits=c(2, 4)) +
  scale_y_continuous(limits = c(0, 1.5)) +
  geom_text_repel(size=3)
```

Where do we move next?


## Better approach: compass search

**Step 4:** If none of the new points is an improvement, try again with half the distance:

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=4, fig.height=2.5}
rss <- function(beta){ sum((Sparrows$Weight - beta[1] -beta[2]*Sparrows$WingLength)^2)}
cur_point <- c(3.3, 0.4)
step_size <- 0.15
test_points <- rbind(cur_point,
                     cur_point + step_size*c(0, 1),
                     cur_point + step_size*c(1, 0),
                     cur_point + step_size*c(0, -1),
                     cur_point + step_size*c(-1, 0))
rss_vals <- apply(test_points, 1, rss)
df <- data.frame(b0 = test_points[,1],
                 b1 = test_points[,2], 
                 rss = rss_vals)
df |>
  ggplot(aes(x = b0, y = b1, label = rss)) +
  geom_point() +
  theme_classic() +
  labs(x = "Beta0", y = "Beta1") +
  scale_x_continuous(limits=c(2, 4)) +
  scale_y_continuous(limits = c(0, 1.5)) +
  geom_text_repel(size=3)
```

Where do we move next?

## Compass search overview (in 2 dimensions)

To minimize some function $f(\beta_0, \beta_1)$:

1. Choose an initial guess $(\beta_0^{(0)}, \beta_1^{(0)})$ and initial step size $\Delta_0$
2. Evaluate $f$ at the points
    * $(\beta_0^{(0)}, \beta_1^{(0)})$
    * $(\beta_0^{(0)}, \beta_1^{(0)} \pm \Delta_0)$
    * $(\beta_0^{(0)} \pm \Delta_0, \beta_1^{(0)})$
3. If $f$ is smaller at one of the new points: move to the smallest value, update to $(\beta_0^{(1)}, \beta_1^{(1)})$
4. Otherwise: $\Delta_{k+1} = 0.5 \Delta_k$ (shrink step size and try again)
5. Repeat

\vspace{3cm}

## Your turn

Practice questions on the course website:

[https://sta379-s25.github.io/practice_questions/pq_10.html](https://sta379-s25.github.io/practice_questions/pq_10.html)

* Practice with compass search
* Start in class. You are welcome to work with others
* Practice questions are to help you practice. They are not submitted and not graded
* Solutions are posted on the course website


